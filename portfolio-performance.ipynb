{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10092419,"sourceType":"datasetVersion","datasetId":6223494}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"PPO vs TD3","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nimport torch\nimport torch.nn as nn\nimport gym\nfrom stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n\n# Adaptive Normalization\nwindow_size = 126  \nrolling_means = returns.rolling(window=window_size, min_periods=1).mean()\nrolling_stds = returns.rolling(window=window_size, min_periods=1).std()\nrolling_stds.replace(0, np.nan, inplace=True)\nadaptive_returns = (returns - rolling_means) / rolling_stds\nadaptive_returns.dropna(inplace=True)\n\n# Ensure 'returns' and 'adaptive_returns' have matching indexes\naligned_returns = returns.loc[adaptive_returns.index].copy()\n\n# Apply PCA to reduced adaptive returns\npca = PCA(n_components=4)\nreduced_features = pca.fit_transform(adaptive_returns)\n\n# K-Means Clustering\nn_clusters = 4  \nkmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\naligned_returns['Cluster'] = kmeans.fit_predict(reduced_features)\n\n# One-Hot Encode Clusters\nohe = OneHotEncoder(sparse=False)\ncluster_features = ohe.fit_transform(aligned_returns[['Cluster']])\ncluster_features_df = pd.DataFrame(cluster_features, columns=[f'Cluster_{i}' for i in range(n_clusters)], index=aligned_returns.index)\n\n# Merge into final dataset\nreturns = pd.concat([aligned_returns.drop(columns=['Cluster']), cluster_features_df], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport gym\nfrom stable_baselines3 import PPO, TD3\nfrom stable_baselines3.common.vec_env import DummyVecEnv\n\n# Custom Portfolio Environment\nclass PortfolioEnv(gym.Env):\n    def __init__(self, returns):\n        super(PortfolioEnv, self).__init__()\n        self.returns = returns\n        self.n_assets = returns.shape[1] - (n_clusters + 1)  # Excluding cluster labels and one-hot features\n        self.observation_dim = self.n_assets + n_clusters  # Ensure correct shape\n        self.action_space = gym.spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(self.observation_dim,), dtype=np.float32)\n        self.current_step = 0\n    \n    def reset(self):\n        self.current_step = 0\n        obs = np.append(\n            self.returns.iloc[self.current_step, :-n_clusters-1].values,\n            self.returns.iloc[self.current_step, -n_clusters:].values\n        )\n        return obs[:self.observation_dim]  \n    \n    def step(self, action):\n        self.current_step += 1\n        done = self.current_step >= len(self.returns) - 1\n        \n        portfolio_return = np.dot(action, self.returns.iloc[self.current_step, :-n_clusters-1].values)\n        volatility = np.std(np.dot(self.returns.iloc[:self.current_step+1, :-n_clusters-1], action))\n        var_threshold = np.percentile(portfolio_return, 5)\n        cvar = np.mean(portfolio_return[portfolio_return <= var_threshold])\n        r2r = portfolio_return / (volatility + 1e-6)\n        \n        reward =  abs(cvar) + r2r\n        obs = np.append(\n            self.returns.iloc[self.current_step, :-n_clusters-1].values,\n            self.returns.iloc[self.current_step, -n_clusters:].values\n        )\n        \n        return obs[:self.observation_dim], reward, done, {\"r2r\": r2r, \"cvar\": cvar, \"portfolio_return\": portfolio_return}\n    \n# Create Environment\nenv = DummyVecEnv([lambda: PortfolioEnv(returns)])\n\n# Train PPO Model\nppo_model = PPO(\"MlpPolicy\", env, verbose=1)\nppo_model.learn(total_timesteps=100000)\n\n# Train TD3 Model\ntd3_model = TD3(\"MlpPolicy\", env, verbose=1)\ntd3_model.learn(total_timesteps=100000)\n\n# Evaluate Performance with clipped rewards\ndef evaluate_model(model, env, print_interval=100, reward_clip_range=(-1, 1)):\n    obs = env.reset()\n    done, rewards, cumulative_returns = False, [], []\n    total_return = 1\n    metrics = {\"r2r\": [], \"cvar\": [], \"portfolio_return\": []}\n    \n    step_counter = 0\n    \n    while not done:\n        action, _ = model.predict(obs)\n        obs, reward, done, info = env.step(action)\n        \n        # Clip rewards to avoid overflow\n        reward = np.clip(reward, reward_clip_range[0], reward_clip_range[1])\n        \n        rewards.append(reward)\n        total_return *= (1 + reward)\n        \n        # Prevent total_return from reaching infinity\n        if np.isnan(total_return) or np.isinf(total_return):\n            total_return = np.clip(total_return, -1e10, 1e10)\n        \n        cumulative_returns.append(total_return)\n        \n        info = info[0]  \n        metrics[\"r2r\"].append(info[\"r2r\"])\n        metrics[\"cvar\"].append(info[\"cvar\"])\n        metrics[\"portfolio_return\"].append(info[\"portfolio_return\"])\n\n        #step_counter += 1\n        \n    return np.mean(rewards), cumulative_returns, metrics\n\nppo_reward, ppo_cum_returns, ppo_metrics = evaluate_model(ppo_model, env)\ntd3_reward, td3_cum_returns, td3_metrics = evaluate_model(td3_model, env)\n\nprint(f\"PPO Metrics - R2R: {np.mean(ppo_metrics['r2r'])}, CVaR: {np.mean(ppo_metrics['cvar'])}\")\nprint(f\"TD3 Metrics -  R2R: {np.mean(td3_metrics['r2r'])}, CVaR: {np.mean(td3_metrics['cvar'])}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert portfolio returns to Pandas Series\nppo_portfolio_return = pd.Series(ppo_metrics[\"portfolio_return\"])\ntd3_portfolio_return = pd.Series(td3_metrics[\"portfolio_return\"])\n\n# Compute rolling volatility (standard deviation over a 6-month window)\nppo_rolling_vol = ppo_portfolio_return.rolling(window=126).std()\ntd3_rolling_vol = td3_portfolio_return.rolling(window=126).std()\n\n# Plot the results\nplt.figure(figsize=(12, 6))\nplt.plot(dates, ppo_rolling_vol, label=\"PPO Rolling Volatility\", color=\"blue\")\nplt.plot(dates, td3_rolling_vol, label=\"TD3 Rolling Volatility\", color=\"red\")\n\nplt.xlabel(\"Date\")\nplt.ylabel(\"Volatility (Rolling 6 Months)\")\nplt.title(\"Rolling Volatility Over Time (6-Month Window)\")\nplt.legend()\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.show()\n\n\n# Summarize portfolio return contributions\nppo_total_return = sum(ppo_metrics[\"portfolio_return\"])\ntd3_total_return = sum(td3_metrics[\"portfolio_return\"])\n\n# Pie chart labels\nlabels = [\"PPO Portfolio Return\", \"TD3 Portfolio Return\"]\nreturns = [ppo_total_return, td3_total_return]\n\n# Define colors\ncolors = [\"blue\", \"red\"]\n\n# Create Pie Chart\nplt.figure(figsize=(8, 6))\nplt.pie(returns, labels=labels, autopct=\"%1.1f%%\", colors=colors, startangle=140, explode=[0.05, 0])\nplt.title(\"Portfolio Return Contribution (PPO vs TD3)\")\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PPO-LSTM","metadata":{}},{"cell_type":"code","source":"# === Custom Portfolio Gym Environment ===\nclass PortfolioEnv(gym.Env):\n    def __init__(self, returns, n_clusters):\n        super(PortfolioEnv, self).__init__()\n        self.returns = returns\n        self.n_assets = len(price_cols)\n        self.n_clusters = n_clusters\n        self.action_space = gym.spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets + self.n_clusters,), dtype=np.float32)\n        self.current_step = 0\n        self.initial_capital = 1.0\n\n    def reset(self):\n        self.current_step = 0\n        self.capital = self.initial_capital\n        obs = np.append(self.returns.iloc[self.current_step, :-self.n_clusters].values, \n                        self.returns.iloc[self.current_step, -self.n_clusters:].values)\n\n        # Ensure correct observation shape\n        obs = self._fix_observation_shape(obs)\n        return np.nan_to_num(obs)\n\n    def step(self, action):\n        self.current_step += 1\n        done = self.current_step >= len(self.returns) - 1\n\n        action = np.nan_to_num(action)\n        action = np.exp(action) / np.sum(np.exp(action))  # Softmax normalization\n        \n        portfolio_return = np.dot(action, self.returns.iloc[self.current_step, :-self.n_clusters].values)\n        self.capital *= (1 + portfolio_return)\n\n        rolling_window = min(126, self.current_step + 1)\n        volatility = np.std(np.dot(self.returns.iloc[self.current_step-rolling_window+1:self.current_step+1, :-self.n_clusters], action))\n        volatility = max(volatility, 1e-6)\n        \n        past_returns = np.dot(self.returns.iloc[:self.current_step+1, :-self.n_clusters], action)\n        var_threshold = np.percentile(past_returns, 5)\n        cvar = np.mean(past_returns[past_returns <= var_threshold]) if np.any(past_returns <= var_threshold) else 0\n        \n        alpha, beta = 0.3, 0.2\n        r2r = portfolio_return / volatility\n        drawdown_penalty = abs(min(0, portfolio_return))\n        reward = r2r - alpha * abs(cvar) - beta * drawdown_penalty\n\n        obs = np.append(self.returns.iloc[self.current_step, :-self.n_clusters].values, \n                        self.returns.iloc[self.current_step, -self.n_clusters:].values)\n\n        # Ensure correct observation shape\n        obs = self._fix_observation_shape(obs)\n        return np.nan_to_num(obs), reward, done, {\"capital\": self.capital, \"r2r\": r2r, \"cvar\": cvar}\n\n    def _fix_observation_shape(self, obs):\n        expected_shape = self.n_assets + self.n_clusters\n        if obs.shape[0] > expected_shape:\n            obs = obs[:expected_shape]  # Truncate if extra\n        elif obs.shape[0] < expected_shape:\n            obs = np.pad(obs, (0, expected_shape - obs.shape[0]), 'constant')  # Pad if missing\n        return obs\n\n# Create Gym Environment\nenv = DummyVecEnv([lambda: PortfolioEnv(returns, n_clusters)])\n\n# === Custom LSTM Feature Extractor ===\nclass LSTMFeatureExtractor(BaseFeaturesExtractor):\n    def __init__(self, observation_space, features_dim=128):\n        super(LSTMFeatureExtractor, self).__init__(observation_space, features_dim)\n        input_dim = observation_space.shape[0]\n        self.lstm = nn.LSTM(input_dim, features_dim, batch_first=True)\n        self.flatten = nn.Flatten()\n\n    def forward(self, observations):\n        observations = observations.unsqueeze(1)\n        lstm_out, _ = self.lstm(observations)\n        lstm_out = self.flatten(lstm_out[:, -1, :])\n        return lstm_out\n\n# Train PPO-LSTM Model\nppo_lstm_model = PPO(\n    \"MlpPolicy\", env,\n    policy_kwargs={\"features_extractor_class\": LSTMFeatureExtractor},\n    gamma=0.993, learning_rate=0.0002, batch_size=128, ent_coef=0.012, verbose=1\n)\nppo_lstm_model.learn(total_timesteps=100000)\n\n# Train Standard PPO Model (without LSTM)\nppo_model = PPO(\n    \"MlpPolicy\", env,\n    gamma=0.91, learning_rate=0.0002, batch_size=64, ent_coef=0.05, verbose=1\n)\nppo_model.learn(total_timesteps=100000)\n\n# Evaluate & Plot Results\ndef evaluate_model(model, env):\n    obs = env.reset()\n    done, cumulative_returns = False, []\n    r2r_values, cvar_values = [], []\n    dates = data['Dates'].iloc[returns.index]\n    \n    while not done:\n        action, _ = model.predict(np.nan_to_num(obs))\n        obs, reward, done, info = env.step(action)\n        cumulative_returns.append(info[0][\"capital\"])\n        r2r_values.append(info[0][\"r2r\"])\n        cvar_values.append(info[0][\"cvar\"])\n    \n    return dates[:len(cumulative_returns)], cumulative_returns, r2r_values, cvar_values\n\n# Evaluate PPO-LSTM\ndates, ppo_lstm_cum_returns, ppo_lstm_r2r, ppo_lstm_cvar = evaluate_model(ppo_lstm_model, env)\n\n# Evaluate PPO\ndates, ppo_cum_returns, ppo_r2r, ppo_cvar = evaluate_model(ppo_model, env)\n\n# Plot PPO, PPO-LSTM Results\nplt.figure(figsize=(10, 5))\nplt.plot(dates, ppo_lstm_cum_returns, label='PPO-LSTM Cumulative Return', color='blue')\nplt.plot(dates, ppo_cum_returns, label='PPO Cumulative Return', color='green')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Return')\nplt.title('PPO vs PPO-LSTM Portfolio Performance')\nplt.legend()\nplt.show()\n\n# Print final performance metrics\nprint(f\"PPO-LSTM R2R: {np.mean(ppo_lstm_r2r):.4f}, CVaR: {np.mean(ppo_lstm_cvar):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute daily portfolio returns from cumulative returns\nppo_lstm_daily_returns = np.diff(ppo_lstm_cum_returns) / ppo_lstm_cum_returns[:-1]\n\n# Compute daily volatility \nppo_lstm_daily_volatility = np.std(ppo_lstm_daily_returns)\n\n# Annualize volatility\nppo_lstm_annual_volatility = ppo_lstm_daily_volatility * np.sqrt(252)\n\nprint(f\"PPO-LSTM Portfolio Annual Volatility: {ppo_lstm_annual_volatility:.4%}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define six-month rolling window (126 trading days)\nrolling_window = 126  \n\n# Convert cumulative returns to daily returns\nppo_lstm_daily_returns = np.diff(ppo_lstm_cum_returns) / ppo_lstm_cum_returns[:-1]\ndates_rolling = dates[1:]  # Align with daily returns\n\n# Compute six-month rolling volatility (annualized)\nrolling_volatility = pd.Series(ppo_lstm_daily_returns).rolling(rolling_window).std() * np.sqrt(252)\n\n# Compute six-month rolling return\nrolling_return = pd.Series(ppo_lstm_cum_returns).pct_change(rolling_window)\n\n# Plot Rolling Volatility & Rolling Return\nfig, ax1 = plt.subplots(figsize=(12, 5))\n\n# Rolling Volatility (Left Y-axis)\nax1.set_xlabel('Date')\nax1.set_ylabel('Rolling Volatility (Annualized)', color='blue')\nax1.plot(dates_rolling, rolling_volatility, label='Rolling Volatility', color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\n\n# Rolling Return (Right Y-axis)\nax2 = ax1.twinx()\nax2.set_ylabel('Rolling Return (6-Month)', color='red')\nax2.plot(dates, rolling_return, label='Rolling Return', color='red', linestyle='dashed')\nax2.tick_params(axis='y', labelcolor='red')\n\n# Formatting\nplt.title('Six-Month Rolling Volatility & Rolling Return Over Time')\nax1.grid(True, linestyle='--', alpha=0.6)\nfig.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport plotly.express as px\n\n# Ensure 'Dates' column is properly formatted\ndata['Dates'] = pd.to_datetime(data['Dates'])\nreturns['Date'] = data.loc[returns.index, 'Dates']  # Aligning 'Date' with 'returns'\n\n# Check if 'Cluster' exists in 'returns', if not, assign it from 'aligned_returns'\nif 'Cluster' not in returns.columns:\n    returns['Cluster'] = aligned_returns['Cluster']\n\n# Ensure 'Cluster' is categorical\nreturns['Cluster'] = returns['Cluster'].astype('category')\n\n# Cluster Distribution Over Time\nplt.figure(figsize=(12, 6))\nsns.histplot(data=returns, x='Date', hue='Cluster', bins=50, palette='tab10', multiple='stack')\nplt.xlabel(\"Date\")\nplt.ylabel(\"Cluster Count\")\nplt.title(\"Cluster Distribution Over Time\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Smoothed Cluster Distribution \ncluster_counts = returns.groupby(['Date', 'Cluster']).size().unstack(fill_value=0)\ncluster_frequencies = cluster_counts.div(cluster_counts.sum(axis=1), axis=0).rolling(30).mean()\n\nplt.figure(figsize=(12, 6))\ncluster_frequencies.plot.area(stacked=True, alpha=0.7, cmap='tab10', figsize=(12, 6))\nplt.xlabel(\"Date\")\nplt.ylabel(\"Cluster Frequency\")\nplt.title(\"Cluster Distribution Over Time (Smoothed)\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Clusters\")\nplt.show()\n\n# Interactive Plot with Plotly\nfig = px.area(cluster_frequencies, x=cluster_frequencies.index, y=cluster_frequencies.columns, \n              title=\"Interactive Cluster Distribution Over Time\", labels={'value': 'Cluster Frequency'})\nfig.update_layout(xaxis_title='Date', yaxis_title='Cluster Frequency')\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}